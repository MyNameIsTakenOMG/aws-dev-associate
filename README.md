# aws-dev-associate

## road map
- [table of lecture contents](#table-of-lecture-contents)
- [lecture hands on](#lecture-hands-on)
- [practice tests](#practice-tests)
- [review lectures and tests](#review-lectures-and-tests)

### table of lecture contents
- [aws iam](#aws-iam)
- [ec2](#ec2)
- [ec2 instance storage](#ec2-instance-storage)
- [HA and scalability](#ha-and-scalability)
- [rds and aurora and elasticache](#rds-and-aurora-and-elasticache)
- [route53](#route53)
- [vpc](#vpc)
- [s3](#s3)
- [aws cli sdk and iam roles and policies](#aws-cli-sdk-and-iam-roles-and-policies)
- [s3 advanced](#s3-advanced)
- [s3 security](#s3-security)
- [cloudfront](#cloudfront)
- [containers](#containers)
- [elastic beanstalk](#elastic-beanstalk)
- [cloudformation](#cloudformation)
- [aws integration and messaging](#aws-integration-and-messaging)
- [aws monitoring and troubleshooting and audit](#aws-monitoring-and-troubleshooting-and-audit)
- [lambda](#lambda)
- [dynamodb](#dynamodb)
- [api gateway](#api-gateway)
- [cicd](#cicd)
- [serverless application model](#serverless-application-model)
- [cdk](#cdk)
- [cognito](#cognito)
- [other serverless](#other-serverless)
- [advanced identity](#advanced-identity)
- [security and encryption](#security-and-encryption)
- [other services](#other-services)


#### aws iam

- iam users & groups
  - user can belong to multiple groups or no group
  - groups can not be nested
- **Global service**
- iam permissions:
  - users & groups can be assigned `policies`
  - in aws, apply the least privilege principle
  - users who belong to multiple groups can inherit permissions from multiple groups policies
- iam password policy
  - allow all iam users to change their own passwords
  - prevent password re-use
  - more...
- mfa: password + code
  - mfa software(authy, google authenticator, support mutliple tokens)
  - hardware(universal 2nd factor:U2F security key, support multi-users with a single key)
  - hardware key fob mfa device: gemalto
  - hardware key fob mfa device for aws govcloud(US): surepassID
- access aws
  - aws console: password + mfa
  - cli: access key
  - sdk: access key
- iam roles for services
- iam security tools
  - iam credentials report: account level
  - iam access advisor: user level



#### ec2

- ec2 capabilities:
  - renting ec2 virtual machines
  - storing data: EBS
  - distributing load: ELB
  - scaling services: ASG
- ec2 sizing & configuration
  - windows, macos, linux
  - cpu, ram
  - storage: instance-store, ebs & efs
  - network card: public ip address
  - security group: firewall
  - user data
- ec2 user data: bootstrap script
  - only run once at the instance first start
  - runs with the root user permissions
- instance types
  - general purpose
  - compute optimized: HPC, ML, gaming server, batching workloads
  - memory optimized: databases, in-memory databases, big unstructured data real-time processing
  - storage optimized: OLTP, databases, in-memory databases, data warehouse, distributed file systems
- security groups
  - only contain `allow` rules
  - stateful, incoming traffic --> outgoing traffic
  - can be attached to multi-instances
  - application timeout error--> security group
  - all inbound traffic is blocked by default
- classic ports:
  - 22: ssh, sftp
  - 21: ftp
  - 80: http
  - 443: https
  - 3389: rdp (remote desktop procotol -- login windows instance)
- ssh & ec2 instance connect
- ec2 purchaing options
  - on-demand
  - reserved instances
  - saving plans
  - spot instances
  - dedicated hosts
  - dedicated instance
  - capacity reservations (combined with RI, Saving Plans)


#### ec2 instance storage

- ebs volume
  - network drive
  - az-scoped
  - have a provisioned capacity
  - root volume: delete on termination(by default)
  - snapshots: no need to detach, but recommended
    - snapshot features:
      - archive
      - recycle bin
      - fast snapshot restore
- ami
  - customization of ec2 instances
  - region-scoped
- instance store:
  - better I/O
  - good for buffer, cache
- ebs volume types
  - gp2/gp3
  - io1/io2: support ebs multi-attach (up to 16 ec2)
  - st1: big data, data warehouse,...
  - sc1: infrequently access
  - gp and io can be used as root volumes
- efs:
  - multi-az
  - nfs protocol
  - for linux
  - encryption using kms
- efs performance & storage classes
  - performance mode
  - throughput mode
  - storage classes: storage tiers, availability


#### HA and scalability

- scalability: vertical, horizontal
- availability: goes hand in hand with horizontal scaling, (running system in at least 2 data centers)
- ELB
  - health check: done on a port and a endpoint
  - types:
    - CLB
    - ALB:
      - layer 7;
      - http/2 and websocket;
      - route to different target groups: ec2(or ec2 in asg), ecs, lambda, private ip
      - fixed hostname
      - to see the client ip, use header: `X-Forwarded-For`
    - NLB: layer 4 (udp, tcp); handle millions of requests per requests; has `one static ip per az`; support EIP(helpful for whitelisting ip addresses)
      - target groups: ec2, private ip, ALB,
      - health check: tcp, http, https
    - GWLB: layer 3; use `GENEVE` procotol on port `6081`
      - manage a fleet of 3rd party network virtual appliance in aws
      - firewalls, intrusion detection, deep packet inspection system
      - target groups: ec2, private ip
  - security group
  - sticky sessions: works for clb, alb, nlb
    - application-based cookies: created by targets(custom cookies) or load balancers(application cookies)
    - duration-based cookies: created by load balancers
  - cross-zone load balancing
    - alb: enabled by default
    - nlb: disabled by default, no free
    - clb: disabled
  - ssl/tls
    - can manage certs using acm
    - or upload your own certs
    - https listener:
      - must specify a default cert
      - can optionally add a list of certs for multi domains
      - client can use SNI(server name indication) to specify which hostname to reach
      - alb and nlb: support multi https listeners; use sni
      - clb: support only one ssl, 
  - ssl -- SNI
    - only works for alb and nlb, cloudfront
  - connection draining(deregistration delay): time to complete `in-flight requests` while the instance is de-registering or unhealthy 
- ASG
  - a launch template
  - cloudwatch alarms & scaling
  - scaling policies:
    - dynamic scaling:
      - target tracking
      - simple/step
    - scheduled scaling
    - predictive scaling
  - metrics for scaling: `CPUUtilization`, `RequestCountPerTarget`, `Average Network In / Out`, or custom metrics
  - scaling cooldowns: when a scaling activity happends, you are in the cooldown period(no launch or terminate instances)
    - use Golden AMIs
  - instance refresh:
    - update launch template and re-create all ec2 instances
    - using native feature: `instance refresh`
    - setting minimum healthy percentage
    - specify `warm-up` time
 

#### rds and aurora and elasticache

- RDS: relational db service
  - support multi different db engines, including aws aurora
  - managed service
  - cannot ssh to the underlying instances
  - storage auto scaling:
    - have to set `Maximum Storage Threshold`
  - read replicas:
    - up to 15
    - within az, cross az or cross region
    - replication is `async`
    - apps must update db connection string
    - replicas can be promoted to their own db
    - use case: data analytics
    - network cost: same-region, free; cross-region charged
  - multi-az (Disaster Recovery):
    - replication: `sync`
    - one DNS name
    - not used for scaling
    - just a standby
    - from single-az to multi-az: click `modify`, then a snapshot is created, then a new db is created, then a synchronization is established
  - rds proxy:
    - fully managed db proxy
    - pool and share db connections
    - reduce rds & aurora failover time
    - must be access from vpc (private)
- Aurora:
  - support mysql and postgres
  - HA & read scaling:
    - 6 copies across 3 az:
      - 4/6 needed for write
      - 3/6 needed for read
      - up to 15 read replicas
      - auto failover
      - cross-region replication
  - aurora db cluster:
    - writer endpoint
    - reader endpoint
  - rds & aurora security:
    - at-rest encryption
    - in-flight encryption
    - iam authentication
    - security groups
    - no ssh except on `rds custom`
    - audit logs can be enabled and sent to cloudwatch logs
- elasticache:
  - managed redis:
    - multi-az and auto failover
    - read replicas with HA
    - backup and restore
  - managed memcached:
    - mutli-node
    - no HA
    - no persistant
    - no backup and restore
    - multi-threading
  - cache must have an invalidation strategy to make sure only the most current data is used in there
  - cache implementation considerations:
    - outdated data
    - data changing slowly or rapidly
    - data structured well or not
  - lazy loading/ cache-aside/ lazy population:
    - cons: cache read miss cause 3 round trips; data could be stale 
  - write through -- add or update cache when db is updated:
    - cons: data missed until it is added or updated in the main db (using lazy loading to solve it); a lot of data will never be read since each time db is updated, it will also update the cache
  - cache evictions and TTL
    - occur in three ways:
      - delete explicitly
      - memory is full and it is not recently used
      - a TTL is set
    - use cases: leaderboards; comments; activity stream
    - consider to scale up or out if eviction happens too frequently
  - final words of wisdom:
    - lazy loading works for many cases, especially on the read side
    - write-through is usually combined with lazy loading as targeted for the queries or workloads
    - set a ttl is usually not a bad idea, except when using write-through
    - only cache things that make sense

  
#### route53

- dns terminologies:
  - domain registar
  - dns records
  - zone file: contains dns records
  - name server: resovle dns queries
  - TLD
  - SLD
- route53:
  - 100 SLA
  - health check
  - records:
    - domain/subdomain name
    - record type
    - value
    - routing policy
    - ttl
  - records types
    - A
    - AAAA
    - Alias
    - CNAME
    - NS
  - hosted zones
    - public
    - private
    - $0.5 per month per hosted zone
  - TTL:
    - except for Alias records
    - high ttl or low ttl
  - CNAME vs Alias
    - CNAME: not for TLD
    - Alias: TLD or non-TLD, point to aws resources
  - Alias records:
    - map hostnames to aws resources
    - no ttl
    - TLD or non-TLD
    - targets:
      - **Note**: not for ec2 instances
      - elb
      - cloudfront
      - api gateway
      - EB
      - s3 websites
      - vpc interface endpoint
      - global accelerator
      - route53 records in the same hosted zone
  - health check:
    - http health check only for public resources
    - but can integrate with cloudwatch metrics to monitor private resources
    - automated dns failover
      - monitor an endpoint:
        - around 15 global health checkers
        - can be configured to only check on the first 5120 bytes of the responses
      - calculated health checks (similar to composite alarms)
      - monitor cloudwatch alarms
  - traffic flow:
    - visual editor to manage complex routing decision trees
    - can be saved as traffic flow policy and applied to different route 53 hosted zones
  - routing policies
    - simple: no health check; route traffic to a single resource
    - weighted:
      - dns records must have the same name and type
      - health check
      - all zero, then traffic evenly distributed
      - if zero, then no traffic sent
      - weights no need to be 100 when summed up
    - latency-based:
      - health check (failover feature)
      - helpful when latency is a priority
    - failover(active-passive)
    - geolocation:
      - should have a default record
      - health check
    - geoproximity
      - shift traffic to resources based on **bias**
      - must use **route 53 traffic flow**
    - ip-based routing
      - routing is based on ip addresses
      - provide a list of CIDRs for clients
    - multi-value:
      - health check
      - same record name and type
- route 53 and other dns registar
  - register a domain name and then use route 53 name servers



#### vpc

- overview -- basics:
  - vpc: private network
  - public subnet
  - private subnet
  - route tables
- internet gateway
- nat gateway (or nat instances:self-managed)
- NACL & security group
  - NACL: allow or deny; subnet level; stateless
  - security group: only allow; ec2 instance/ENI; stateful
- vpc flow logs:
  - vpc flow logs, subnet flow logs, ENI flow logs
  - logs can go to s3, KDF, cloudwatch logs
- vpc peering:
  - connect two vpc, privately using aws network
  - must not have overlapping CIDR
  - not transitive
- vpc endpoints:
  - gateway endpoints: s3, dynamodb
  - interface endpoint: for DX, s2s vpn
    - public virtual interface
    - private virtual interface
- s2s vpn & DX
  - s2s vpn: on-prem to aws; use public internet; encrypted
  - DX: take a long time to build; private connection; physical connection; private network



#### s3

- buckets:
  - regional service
  - needs a global unique name
- objects
  - the key is the full path: prefix + object name
  - max object size: 5tb
  - muse use `multi-part upload` if size > 5gb
- s3 security:
  - user-based: iam policies
  - resources-based:
    - bucket policies
    - object access control list -- fine-grained
    - bucket access control list -- less common
  - encryption
- s3 static website hosting:
  - make sure the bucket policy allows public access
  - make sure the bucket name is the same as the record name
- s3 versioning
  - enable at bucket level
- s3 -- replication
  - must enable versioning
  - cross-region replication
  - same-region replication
  - asynchronous copy
  - using `s3 batch replication` to replicate existing objects
  - can replicate `delete marker`
  - there is no chaining replicaiton
- s3 storage classes
  - standard
  - infrequent access:
    - standard-IA
    - one zone-IA
  - glacier storage classes
    - instant retrieval
    - flexible retrieval
    - deep archive
  - intelligent-tiering


#### aws cli sdk and iam roles and policies

- ec2 instance metadata (IMDS)
  - allow ec2 to `learn about themselves` without using an iam role
  - can retrieve the iam role from the metadata, but not the iam policy
- IMDS v2 and IMDS v1
- MFA with CLI
  - must create a temporary session using `sts getsessiontoken` api call
- aws sdk
- aws limits (quotas)
  - api rate limits
  - service quotas (service limits)
- exponential backoff
  - use exponential backoff if you encounter `ThrottlingException`
  - retry logic has been included in aws sdk (not for conditional check)
    - must only implement the retry for 5xx errors and throttling
    - do not implement on 4xx client errors
- aws cli credentials provider chain
  - command line options
  - environment variables
  - cli credentials file -- aws configure: `~/.aws/credentials`, `~/.aws/config`
  - container credentials for ecs tasks
  - instance profile credentials for ec2 instance profiles
- aws sdk default credentials provider chain(java)
  - java system properties
  - environment variables: access_key, access_secret
  - default credential profile file: for example `~/.aws/credentials`
  - ecs container credentials for ecs containers
  - instance profile credentials for ec2 instances
- aws credentials best practices
  - never store aws credentials in your code
  - if working with aws, use iam roles
  - if working outside of aws, use environment variables/ named profiles
- sign aws api requests
  - if use sdk or cli, the requests are signed for us



#### s3 advanced

- moving between storage classes
  - using `lifecycle rules`
- lifecycle rules:
  - transition actions
  - expiration actions
  - can be create for certain prefix or object tags
- s3 analytics -- storage class analysis
  - recommendations for standard and standard IA
  - good first step to put together lifecycle rules
- s3 event notifications
  - sns
  - sqs
  - lambda
  - eventbridge:
    - advanced filtering options with json rules
    - multi-destinations
    - eventbridge capabilities
- s3 performance
  - 3,500 put/copy/post/delete per prefix
  - 5,500 get/head per prefix
  - multi-part upload: must use > 5gb
  - s3 transfer acceleration
  - s3 byte-range fetches
    - parallelize get requests
    - can be configured to only fetch part of the data
- s3 select & glacier select
  - less network transfer
  - can filter rows and columns
  - can retrieve less data using sql
- s3 user-defined object metadata & s3 object tags
  - we cannot search the object metadata or object tags
  - instead, we must use external db as a search index, such as dynamodb


#### s3 security

- object encryption
  - sse-s3: use the key managed and owned by aws s3
    - header: "x-amz-server-side-encryption": "AES256"
  - sse-kms: use aws kms to manage the key
    - header: "x-amz-server-side-encryption": "aws:kms"
    - audit using cloudtrail
    - kms limit
  - sse-c: encryption key is managed by you
    - https is a must
    - the key must be provided every request
    - aws only handle encryption
  - client-side encryption: cse
    - use client libraries like: Amazon S3 Client-Side Encryption Library
    - clients handle encryption and decryption
- encryption in transit
  - ssl/tls
  - bucket policy condition: `aws:SecureTransport:`
- default encryption vs bucket policies
  - **note**: bucket policies are evaluated before default encryption
- s3 cors
  - we need to enable correct cors headers for clients to fetch
- s3 MFA delete
  - only root account can enable/disable MFA delete
  - no need: enable versioning; list deleted versions
  - need: permanently delete version; suspend versioning
- s3 access logs
  - set a target bucket(different) for storing access logs
- pre-signed urls
  - use cli, sdk, console to create pre-signed urls
- s3 access points
  - has its own domain
  - an access point policy
- s3 access points -- vpc origin
  - between the vpc gateway endpoint or interface endpoint and s3 buckets
  - vpc endpoint policy must allow access to the target bucket and access point
- s3 object lambda
  - architecture:
    - client
    - s3 object lambda access point
    - lambda
    - s3 access point
  - use cases:
    - redacting personal info before send them back to the caller
    - converting data formats or resizing images

  
#### cloudfront

- overview:
  - cdn
  - DDoS protection, integrated with aws shield, aws waf
- origins
  - s3 buckets:
    - OAC
  - custom origins:
    - s3 websites
    - alb
    - ec2
    - any http backend
- cloudfront vs s3 cross-region replication
  - cloudfront: good for static content availablt anywhere
  - s3: good for dynamic content available in a few regions
- caching
  - at edge locations
  - identify each object using `cache key`
  - increase the cache hit ratio and decrease requests to the origin
  - invalidation: `CreateInvalidation` api
- cache key:
  - unique identifiers for each object
  - hostname + resource portion of the url
  - can add other elements: http headers, cookies, query strings using `cache policies`
- cache policies:
  - http headers:
    - none
    - whitelist
  - cookies
  - query strings
    - none
    - whitelist
    - inlude all-except
    - all (not good, too many)
  - control TTL, can set by the origin using `Cache-Control` header
  - custom policies support
  - **note**: all http headers, cookies, query strings in `cache key` are included in origin requests
- origin request policy
  - Specify values that you want to include in origin requests without
including them in the Cache Key (no duplicated cached content)
  - can include: http headers, cookies, query strings
  - ability to add cloudfront http headers and custom headers to an origin requst that was not included in the viewer request
  - support custom policy
- cache invalidations
  - we can force an entire or partial cache refresh by performing cloudfront invalidations
  - can specify invalidation path: `*`, `/images/*`
- cache behaviors
  - configure different settings based on the content type or path pattern: `/api/*`, `/*`
  - the default cache behavior is always the last to be process and is always `/*`
- geo restriction
  - restrict who can access your distribution:
    - allowlist
    - blocklist
- signed url / signed cookies (normally after authentication and authorization)
  - for example, only premium users can access paid shared content
  - can attach a policy with:
    - url expiration
    - ip ranges
    - trusted signers (which aws accounts can create signed url)
  - signed url: individual files
  - signed cookies: multi files
- cloudfront signed url vs s3 pre-signed url
  - cloudfront:
    - filter by ip, path, data, expire
    - define access path
    - only root user can manage it
    - utilize caching features
  - s3:
    - uses iam key
    - issue a request as the person who pre-signed the url
- cloudfront signed url process
  - signers:
    - a trusted key group(recommended)
    - an aws account that has a cloudfront key pair(not recommended, should not use root account)
  - can create multi key groups
  - generate key pair
- price classes
  - all
  - 200: most regions, exluding the most expensive ones
  - 100: only the least expensive ones
- multiple origins
  - route to different origins based on the content type
  - based on path pattern: `/images/*`, `/api/*`
- origin groups
  - increate HA and do failover
  - one origin group: one primary and one secondary origin
- field level encryption
  - protect sensitive user info for each request
  - encryption at the edge locations
  - specify fields(max 10) to encrypt and public key used for encryption
  - decryption at the web server side
- real-time logs
  - using KDS
  - choose:
    - sampling rate
    - specify fields and cache behaviors(path patterns)



#### containers

- overview:
  - apps are packaged in containers that can run on any os
  - docker image repositories:
    - docker hub
    - aws ecr
- docker vs virtual machines
  - docker containers are sharing the resources
- docker containers management on aws
  - aws ecs
  - aws eks
  - aws fargate: serverless container platform, working with ecs and eks
  - ecr: storing container images
- aws ecs
  - ec2 launch type
    - each ec2 must have ecs agent to register in the ecs cluster
    - aws takes care of starting / stopping containers
    - ecs tasks: launch ec2 instances on ecs clusters
  - fargate launch type
    - no ec2 instances to manage
    - just take care of task definitions
    - aws runs ecs tasks for your based on cpu / ram you need
    - to scale, just increase the number of tasks
  - iam roles
    - ec2 instance profile: (ec2 launch type only)
      - used by ecs agent
      - make api calls to ecs service
      - send logs to cloudwatch logs
      - pull images from ecr
      - reference data in secrets manager or ssm parameter store
    - ecs task role
      - each task has a role
      - defined in task definition
  - load balancer integrations
    - alb: most use cases
    - nlb: only for high thoughput
    - clb: not recommended
  - data volumes (efs: serverless)
    - mount EFS onto ecs tasks
    - works for ec2 and fargate types
    - **note**: s3 cannot be used as file system
  - ecs auto scaling
    - uses aws application auto scaling
    - based on : cpu, ram, or alb requests count per target
    - target tracking
    - step scaling
    - scheduling schaling
    - ecs auto scaling (task level)
    - ec2 auto scaling (instance level)
  - ec2 launch type -- auto scaling ec2 instances
    - scaling by adding ec2 instances
    - asg
    - ecs cluster capacity provider: paired with asg
  - rolling updates
    - min: minimum healthy percent (relative to the actual running capacity: 100%) 
    - max: maximum percent (actual running capacity + allowed to create tasks: extra)
  - integrated with eventbridge:
    - on-schedule
    - on-demand
  - integrated with sqs
  - task definitions:
    - json form to tell ecs how to run a docker container
    - cpu, ram, iam role, image, port, logging, env, networking
    - up to 10 containers in one task definition
  - load balancing:
    - ec2 launch type:
      - dynamic host port mapping if the container port is defined in the task definition
      - alb will find the right port
      - must allow ec2 security group to any port from alb security group
    - fargate
      - each task has a private ip
      - only container port
      - one iam role per task definition
  - environment variables
    - hardcoded
    - ssm parameter store
    - secrets manager
    - env files(bulk) -- s3
  - data volumes (bind mounts)
    - share data between multi container in the same task definition
    - works for both ec2 and fargate
  - task placement (only for ec2 launch type)
    - task placement contraints
      - distinctInstance: tasks are placed on different instances
      - memberOf: placed on ec2 instances with a specified expression; or uses the cluster query language(advanced)
    - task placement strategies: best effort
      - binpack: aim the least available amount of cpu and ram
      - random
      - spread: tasks are spread evenly based on the specified value: az
      - or mix them up
    - task placement process:
      - identify the proper ec2 instance
      - identify the instance with task placement contraints
      - identify the instance with task placement strategies
      - select the instance
- ecr
  - container images registry
  - integrated with ecs
  - public and private
- aws copilot
  - help run apps on AppRunner, ECS, and fargate
  - help focus on building apps rather than setting up infra
  - provision all required infra for containerized apps
  - auto-deploy using codepipeline
  - deploy to multiple env
  - troubleshooting, logs, health status
- aws eks
  - aws managed kubernates cluster
  - eks supports ec2 and fargate
  - cloud-agnostic
  - collect logs and metrics using cloudwatch container insights
  - Node Types:
    - managed node group: create and manage nodes(ec2 instances) for you
    - self-managed nodes: you create nodes and register to the cluster and then managed by asg
    - aws fargatea
  - data volumes (file systems)
    - need to specify storageClass manifest on your eks cluster
    - leverages a container storage interface compliant driver
    - support:
      - ebs
      - efs (works with fargate)
      - fsx for lustre
      - fsx for netapp ontap



#### elastic beanstalk

- overview:
  - provision underlying resources: elb, asg, ec2, rds,...
  - managed service
  - web server tier & worker tier
  - devs only need to take care of application codes
  - still have full control over the configuration
- components
  - applications
  - application versions
  - environments: each application version
- deployment modes:
  - single instance
  - HA
- deployment options for updates
  - all at once
  - rolling (manual rollback)
  - rolling with addtional batches (manual rollback)
  - immutable: create a new asg with new versions, then swap to the new asg; high cost, long deployment, quick rollback(just terminate the asg, good for prod)
  - blue/green: (not a direct feature, need to work with route53 using weight policy and then swap urls when ready) create a new environment and switch over when ready
  - traffic splitting: (using the alb to do traffic splitting) canary testing -- send small portion of traffic to the new deployment. can trigger an automated rollback(very quick), new instances migrate to the original asg, old verion will be terminated. deployment health is moinitored
- deployment process
  - describe dependencies
  - package code as zip and describe dependencies
  - use console or cli to upload zip and then deploy
- lifecycle policy
  - EB can store up to 1000 app versions
  - to phase out old app versions, use lifecycle policy
    - based on time
    - based on space
  - the in-use version cannot be deleted
  - Option not to delete the source bundle in S3 to prevent data loss
- extensions
  - a zip file containing our code must be deployed to EB
  - all parameters set in UI can be configured with code using files
  - requirements:
    - must be in the path `.ebextensions/` directory in the root of source code
    - yml/json
    - .config extensions (exmaple: logging.config)
    - able to add other aws resources
    - able to modify some default settings using : `option_settings`
- under the hood
  - using cloudformation
  - can define cloudformation resources in your .ebextensions directory
- cloning
  - clone an environment
  - all resources and configuration are preserved
    - data in db is not preserved
- EB migration: load balancer
  - the load balancer type cannot be changed(clb, nlb,alb)
  - create a new environment with different type of load balancer, then swap CNAME or route 53 update
- EB with RDS
  - database lifecycle is tied to the EB environment lifecycle
  - good practice is to create a rds instance separately and provide our environment with the connection string
- EB migration: decouple RDS
  - create a snapshot of db (safeguard)
  - go to rds console to enable deletion protection
  - create a new environment but without rds, instead, just point to the existing rds instance
  - then perform CNAME swap (blue/green) or route53 update
  - terminate the old environment (rds will stay)
  - delete the cloudformation stack(in DELETE_FAILED state, cuz the rds unable to delete)


#### cloudformation

- benefits:
  - infra-as-code: good for version control
  - cost: good for cost management using tags (saving strategy)
  - productivity: quickly recreation
  - separation of concerns: multi stacks
- process:
  - template
  - s3 bucket
  - aws cloudformation
  - create stack to provision resources
- deployment
  - manual
  - automated
- cloudformation -- resources
- cloudformation -- parameters
  - to reference a parameter: using `!Ref`
  - pseudo parameters (provided by aws)
- cloudforamtion -- mappings
  - use `!FindInMap` to return a value from the map
- cloudformation -- outputs
  - declare optional outputs
  - using `Export` section
  - using `!ImportValue` to reference
- cloudformation -- conditions
  - intrinsic functions(logical)
  - can be applied to resources, outputs,... but not `parameters`
- cloudformation -- intrinsic functions
  - !GetAtt: get the attributes of the resources
  - !Base64: use to encode user data for ec2 for example (convert string to base64)
  - condition functions
- rollbacks
  - creation fails
  - update fails
  - rollback fails: manual fix, then call `ContinueUpdateRollback` api to continue rollback
- service role
  - iam users with the iam role which include `iam:PassRole` permission
  - make sure iam users have the least privileges
- cloudformatin capabilities
  - CAPABILITY_NAMED_IAM & CAPABILITY_IAM
  - CAPABILITY_AUTO_EXPAND
  - InsufficientCapabilitiesException
- deletion policy -- for stack resources
  - delete: won't work with s3 bucket if it is empty
  - retain: work with resources
  - snapshot
- stack policy -- for stack updates
  - define update actions that are allowed during stack updates
  - must explicitly allow
- termination protection -- for stack deletes
- custom resources
  - define custom resources
  - have custom logic (scripts) via lambda
  - service token specify where to send the requests(lambda, sns)
  - use case: empty s3 bucket before deleting it
- stacksets
  - create, update, delete stacks across multi accounts and regions
  - can be applied within an aws organization


#### aws integration and messaging

- decouple your applications(scale independently from our applications):
  - sqs: queue model
  - sns: pub/sub model
  - kinesis: real-time streaming model
- sqs:
  - standard queue:
    - unlimited throughput, unlimited number of messages in queue
    - low latency
    - 256kb max size of each message
    - retention: 4 - 14 days
    - best-effort, at least once delivery
  - producing messages
    - sendMessage api call
    - message is persisted until a consumer deletes it
  - consuming messages
    - ec2, lambda,...
    - poll messages (up to 10)
    - process messages
    - delete message using deleteMessage api call
  - multi ec2 consumers
    - poll and process messages in parallel
    - scale consumers horizontally to increase throughput
  - with asg
    - scaling based on an alarm set on the cloudwatch metric: ApproximateNumberOfMessages
  - decouple between application tiers
  - security
    - encryptioin in-transit and at rest
    - or client side encryption
  - queue access policy
    - resource-based policy
  - message visibility timeout
    - a message is invisible when it is polled
    - by default 30 seconds, then after that, it becomes visible again
    - consumer call the ChangeMessageVisibility api    
  - dead letter queue
    - a message will be sent to a dlq after being failed to be processed
    - configure `MaximumReceives`
    - standard queue -- standard dlq queue
    - fifo queue -- fifo dlq queue
    - good to set retention of 14 days in the dlq
    - redrive to source
      - when our code is fixed, we can redrive messages from dlq to the source queue(or any other queue) in batches without writing custom code
  - delay queue
    - delay a message up to 15 mins
  - long polling
    - can optionally wait if there is no message in the queue
    - decrease the number of api calls
    - is preferable to short polling
    - can enable at queue level
  - extended client
    - max size of each message is 256kb
    - to send data like 1GB, use `SQS extended client`(java library)
  - must know api
    - CreateQueue
    - DeleteQueue
    - PurgeQueue
    - SendMessage, ReceiveMessage, DeleteMessage
    - MaxNumberOfMessages (up to 10, for receiving messages api)
    - ReceiveMessageWaitTimeSeconds: long polling
    - ChangeMessageVisibility
    - batch apis for sending, deleting, changing messages visibility: help decrease your costs
  - fifo queue
    - limited throughput: 300 per second, 3000 per second with batch
    - exactly once delivery
    - messages processed in order
    - deduplication
      - interval is 5 min
      - two methods:
        - Content-based deduplication: will do a SHA-256 hash of the message body
        - Explicitly provide a Message Deduplication ID
      - prevent producers from sending duplicated messages
    - message grouping
      - same value for MessageGroupID in fifo queue
      - ordering inside the group is kept
      - ordering across groups is not guaranteed
      - each group has different consumer
- aws SNS
  - pub/sub: send one message to many receivers
  - one event producer can only send messages to one sns topic
  - many event receivers or subscribers can listen to one sns topic
  - Each subscriber to the topic will get all the messages (note: new feature to filter messages)
  - integrated with many aws services as message senders
  - how to publish
    - topic publish using sdk
    - direct publish for mobile apps sdk
  - security: similar to sqs
  - sns + sqs: fan out
    - can add more sqs subscribers over time
  - fifo topic
    - similar to fifo queue
    - message group id (all messages ordered in the same group)
    - deduplication
    - **note**: can have sqs standard or fifo as subscribers
    - limited throughput
  - message filtering
    - subscribers use it to filter messages based on their needs
    - otherwise all message will be received
- aws kinesis
  - collect, process, and analyze streaming data in real-time
  - kinesis data streams
    - retention: 1-365 days
    - support replay
    - data in kinesis is immutable, cannot be deleted
    - data with the same partition key goes to the same shard (ordering)
    - capacity modes
      - provisioned mode:
        - choose number of shards
        - each shard: 1mb in , 2mb out per second
      - on-demand mode:
        - default capacity provisioned: 4mb in or 4000 records per second
    - security
      - using iam policy
      - encryption in-transit and at rest or choose client-side encryption
      - vpc endpoint is available for kinesis
      - monitoring using cloudtrail
    - producers
      - data record: sequence number; partition key, data blob
      - aws sdk, kinesis producer libracy(KCL), kinesis agent
      - putRecord api
      - 1mb or 1000 records per sec per shard
      - use batching with putRecord api
      - use highly distributed partition key to avoid hot partition
      - `ProvisionedThroughputExceeded`
        - use highly distributed partition key
        - increase shards
        - retry with exponential backoff
    - consumers
      - max 5 consumers per shard
      - lambda, kda, kdf, kcl, custom consumer(aws sdk -- classic or enhanced fan-out)
      - custom consumer
        - classic: multi consumers share 2mb out; max 5 getRecord api/sec
        - enhanced fan-out: multi consumers have 2mb out each
      - lambda
        - support classic and enhanced fan-out consumers
        - read records in batches
        - can configure batch size and batch window
        - retry
        - can process up to 10 batches per shard simultaneously
      - KCL
        - java library
        - each shard to be to read by only one kcl instance
        - progress is checkpointed into dynamodb
        - can run on ec2, on-prem, EB
        - track other workers and share the work amongst shards using dynamodb
        - records are read in order at shard level
        - one kcl can read multi shards
    - kinesis operation -- shard splitting
      - used to increase stream capacity (1mb in per shard)
      - divide hot shard
      - no auto scaling, just manual
      - cannot split into more than 2 shards at a time
      - the old shard will be closed and deleted once the data is expired
    - kinesis operation -- merging shards
      - decrease the stream capacity and save costs
      - group two shards with low traffic(cold shards)
      - cannot merge more than 2 shards at a time
      - the old shard will be closed and deleted once the data is expired
  - kinesis data firehose
    - fully-managed, auto scaling, serverless
    - pay for data going into firehose
    - near real time
      - buffer size: minimum 1mb
      - buffer interval: 0 - 900 sec
    - support data multi format, conversions, transforms, and compression
    - support custom data transform using lamdba
    - can send failed data to s3 bucket
    - no data storage
    - no replay
  - kinesis data analytics
    - sql application:
      - real time analytics on kds and kdf using sql
      - add reference data from s3 to enrich streaming data
      - fully-managed, serverless
      - auto scaling
      - pay-as-you-go
      - output: kds, kfd
    - apache flink( java, scala, or sql)
      - source: kds, aws msk
      - no kdf
  - kinesis video streams
  - ordering data into kinesis using partition key
  - ordering data into sqs using fifo queue (no need group ID, unlike sns), with `only one consumer`
    - to add more consumers, use group ID, similar to partition key in kinesis
  - kinesis vs sqs ordering



#### aws monitoring and troubleshooting and audit

- importance of monitoring
  - deploy applications:
    - safely
    - automated
    - infra-as-code
    - leverage aws managed services
  - app users:
    - latency
    - outage
    - communicate with it support
    - troubleshooting and remediation
  - internal monitoring
    - can we prevent issues before they happen
    - performance and cost
    - trends(scaling patterns)
    - learning and improvement
- monitoring in aws
  - aws cloudwatch
    - metrics
    - logs
    - events
    - alarms
  - aws x-ray
    - troubleshooting application performance and errors
    - distributed tracing of microservices
  - aws cloudtrail
    - api calls
    - auditing
- cloudwatch metrics
  - for every aws service
  - metric is a variable
  - belong to namespaces
  - determined by dimensions
  - have timestamps (at second granularity, cloudwatch will aggregate multi data points if they are in the same timestamp)
  - can create custom dashboards
- ec2 detailed monitoring
  - 1 min interval
  - will scale faster when using asg
  - aws free tier allows 10 detailed monitoring metrics
- custom metrics
  - possible to send custom metrics
  - example, memory usage, disk space, number of logged in users,...
  - can use dimensions to segment metrics
  - metric resolution:
    - standard: 1min
    - high resolution: 1/5/10/30 seconds
    - **note**: accept metric data points two weeks in the past and 2 hrs in the future
- cloudwatch logs
  - log groups
  - log stream
  - log expiration
  - cloudwatch logs can be sent to s3, kds, kdf, lambda, opensearch
  - encrypted by default
  - can set kms custom key
  - sources:
    - sdk, cloudwatch agent,
    - EB
    - ecs
    - aws lamdba
    - api gateway
    - cloudtrail
    - route53
- cloudwatch log insights
  - search and analyze log data
  - can query multi log groups in different aws accounts
  - it is a query engine, not a real-time engine
- cloudwatch log -- s3 export
  - can take up to 12 hrs, not near real time
- cloudwatch log subscriptions
  - real-time log events
  - lambda, kdf, kds
  - subscription filter
  - cross-account subscription
- cloudwatch logs aggregation multi-account & multi-region
- cloudwatch logs for ec2
  - need to run cloudwatch agent with iam permission
  - cloudwatch agent can be set on-prem
- cloudwatch logs agent & unified agent
  - unified agent: new version
    - centralized configure using ssm parameter store
    - collect additional system-level metrics
    - by default: disk, cpu, network
- cloudwatch logs metric filter
  - can use filter expression
  - not retroactive
  - able to specify up to 3 dimensions for metric filter
- cloudwatch alarms
  - triggered by any metric
  - period:
    - length of time to evaluate the metric
    - high resolution custom metrics: 10, 30, or multi of 60 sec
  - targets:
    - ec2
    - ec2 auto scaling
    - sns
  - composite alarms
    - monitor multi alarms states
    - help reduce alarm noise
  - ec2 instance recovery:
    - status check
    - recovery: same private, public, EIP, metadata, placement group
  - good to know
    - alarms can be created on cloudwatch logs metric filter
  - synthetics canary
    - aws version of e2e tests
    - integrated with alarms
    - blueprints:
      - heartbeat monitor
      - api canary
      - broken link checker
      - visual monitoring
      - canary recorder
      - GUI workflow builder
- aws eventbridge
  - schedule: cron jobs
  - event patterns
  - trigger lamdba, send sqs, sns,...
  - event buses
    - can be accessed by other aws accounts
    - can archive event
    - can replay event
  - schema registry
    - eventbridge can analyze and infer the schema
    - allow to create custom registry
    - can be versioned
  - resource-based policy
  - multi-account aggregated
- aws x-ray
  - great for distributed system with a plenty of microservices
  - review request behavior
  - check service sla
  - check if throttled
  - integration:
    - lambda
    - EB
    - ecs
    - elb
    - api gateway
    - ec2 or on-prem
  - leverages tracing
    - tracing: e2e way to follow a request
    - each service will add its own `trace`
    - tracing is made of segments (subsegments)
    - annotations: add extra info
    - security: iam, kms
    - able to trace:
      - every request
      - sample request (%, for example 3%)
  - to enable x-ray
    - using aws x-ray sdk
    - each application must have iam rights to write data to x-ray
  - x-ray magic:
    - collect data from different services
    - service map is computed from all segments and traces
    - x-ray is graphical, non-technical people can help
  - troubleshooting:
    - on ec2:
      - check the iam permission
      - check the x-ray daemon
    - on lambda:
      - check iam permission
      - enable lambda x-ray active tracing feature
      - ensure x-ray client initialized in the code
  - intrumentation in the code
    - the measure of productâ€™s performance, diagnose errors, and to write trace information.
    - to instrument your application code, using sdk
    - can custom annotations using interceptors, filters, handlers, middlewares,...
  - concepts:
    - segments
    - subsegments
    - trace
    - sampling: decrease the amount of request sent to x-ray
    - annotations: key-value pairs used to `index` traces with `filters`
    - metadata: not indexed
  - sampling rules:
    - control the amount of data sent to x-ray
    - By default, the X-Ray SDK records the first request `each second`, and `five percent` of any additional requests.
    - `One request per second is the reservoir`, which ensures that at least one trace is recorded each second as long the service is serving requests.
    - `Five percent is the rate` at which additional requests beyond the reservoir size are sampled.
  - custom sampling rules
  - x-ray write apis
  - x-ray read apis
  - x-ray with elastic beanstalk
    - EB platform include x-ray daemon
    - can enable by setting an option via eb console or with a configuration file (in the .ebextensions/xray-daemon.config)
    - remember to check the ec2 iam permission and x-ray sdk
    - **note**: x-ray daemon is not provided for multi-container docker
  - ecs + x-ray
    - x-ray daemon as a separate container
    - x-ray daemon as a sidecar container with the main container
    - for fargate cluster
      - x-ray daemon as a sidecar container
- aws distro for openTelemetry
  - open source version of aws x-ray
  - a standard set of apis to multiple destinations 
- aws cloudtrail
  - enabled by default
  - get a history of events/api calls made within aws account
  - a trail can be applied to all regions or a single region
  - Provides governance, compliance and audit for your AWS Account
  - cloudtrail events
    - management events (enabled by default), can separate `read events` and `write events`
    - data events (not enabled by default due to a large amount of operations)
    - cloudtrail insights events (findings)
  - event retention: 90 days, or choose to send them to s3 bucket
  - integration with eventbridge



#### lambda
#### dynamodb
#### api gateway
#### cicd
#### serverless application model
#### cdk
#### cognito
#### other serverless
#### advanced identity
#### security and encryption
#### other services

- aws ses
  - fully managed
  - allow inbound/outbound emails
  - reputation dashboard, anti-spam feedback, performance insights
  - Supports DomainKeys Identified Mail (DKIM) and Sender Policy Framework (SPF)
  - Flexible IP deployment: shared, dedicated, and customer-owned IPs
  - Send emails using your application using AWS Console, APIs, or SMTP
  - Use cases: transactional, marketing and bulk email communications
- aws opensearch service
  - successor to aws elasticsearch
  - with opensearch, we can search any field, or partially matches
  - complement to other databases like dynamodb
  - managed cluster or serverless cluster
  - does not natively support SQL (via a plugin)
  - come with dahsboard
  - integrated with kdf, iot, cloudwatch logs
  - kds(real time with a lambda) or kdf(near real time with a lambda doing data transformation)
  - cloudwatch logs: subscription filter + lambda/kdf
- aws athena
  - serverless query service --> s3
  - using standard sql
  - used with quicksight for data visualization
  - performance improvement:
    - columnar data(less scan)
    - compress data for smaller retrievals
    - use larger file(> 128mb) to minimize overhead
    - partition datasets
  - federated query
    - use `data source connector` running on aws lambda
- aws managed streaming for apache kafka
  - alternative to aws kinesis
  - fully managed kafka on aws
    - allow to create, update, delete clusters
  - msk serverless
    - without mananing the capacity
  - aws kds vs aws msk
    - kds:
      - 1mb message size
      - data stream with shards
      - shard splitting & merging
      - encryption in-transit and at rest
    - msk:
      - 1mb default, up to 10mb message size
      - kafka topics with partitions
      - can only add partition to a topic
      - encryption in-transit and at rest
    - consumers:
      - kda
      - aws glue for ETL
      - lambda
      - ec2, ecs,eks
- aws acm
  - ssl/tls certificates
  - auto tls renewal
  - integrated with
    - EB
    - cloudfront distro
    - api gateway
    - alb     
- aws private certificate authority (CA)
  - managed service to create private CA (root, subordinaries)
  - issue x.509 certificates
  - certificates only trusted within your organization(not public)
  - work for the services that are integrated with acm
  - use cases:
    - authenticate users, computers, api endpoints, iot
    - enterprises build public key infra
    - encrypt tls communication, cryptographically signing code
- aws macie
  - detect PII or users sensitive data in s3
- aws appConfig
  - configure, validate, and deploy dynamic configurations
    - no need to restart the application
  - used with apps on ec2, lambda, ecs, eks,...
  - gradually deploy changes and rollback if need
- cloudwatch evidently
  - Safely validate new features by serving them to a specified % of your users
  - Launches (= feature flags): enable and disable features for a subset of users
  - Experiments (= A/B testing): compare multiple versions of the same feature
  - Overrides: pre-define a variation for a specific user
  - Store evaluation events in CloudWatch Logs or S3


### lecture hands on


### practice tests

- practice exam:
  - 1st try: 61% (40/65)

### review lectures and tests







